# coding: utf-8
import warnings
import gc
import pickle
import time
import kaggle
import os


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import lightgbm as lgb

from datetime import datetime as dt

from sklearn.model_selection import KFold


from sklearn.metrics import mean_squared_error
warnings.simplefilter(action='ignore', category=FutureWarning)
from sklearn import metrics

"""
E60
- num_thread benchmark
"""
print("script started: ", time.strftime("%b %d %Y %H:%M:%S"))


experinment_nr = 60
train_fname = '../input/train_catboost.pkl.gz'
test_fname = '../input/test_catboost.pkl.gz'

train = pd.read_pickle(train_fname, compression='gzip')
print("TRAIN LOADED")


target = pd.read_pickle('../input/target.pkl.gz', compression='gzip')


true_numerical_columns = [
    'Census_ProcessorCoreCount',
    'Census_PrimaryDiskTotalCapacity',
    'Census_SystemVolumeTotalCapacity',
    'Census_TotalPhysicalRAM',
    'Census_InternalPrimaryDiagonalDisplaySizeInInches',
    'Census_InternalPrimaryDisplayResolutionHorizontal',
    'Census_InternalPrimaryDisplayResolutionVertical',
    'Census_InternalBatteryNumberOfCharges'
]

binary_variables = [c for c in train.columns if train[c].nunique() == 2]

categorical_columns = [c for c in train.columns if c not in true_numerical_columns]


#max_iter = 3

gc.collect()

print("TRAIN PREPARED")


test = pd.read_pickle(test_fname, compression='gzip')
print("TEST LOADED")


# with open('../input/categoricals.pkl', 'rb') as pickle_file:
#    categorical_columns = pickle.load(pickle_file)
#
#print("Categorical columns loaded:", categorical_columns)

gc.collect()


params = {
    'physical_cores': {
        'num_threads': 28,
        'num_leaves': 60,
        'min_data_in_leaf': 60,
        "boosting": "gbdt",
        'objective': 'binary',
        "metric": 'auc',
        'max_depth': -1,
        'learning_rate': 0.2,
        "feature_fraction": 0.8,
        "bagging_freq": 1,
        "bagging_fraction": 0.8,
        "bagging_seed": 11,
        "lambda_l1": 0.1,
        "random_state": 133,
        "verbosity": -1
    },
    'logical_cores': {
        'num_threads': 56,
        'num_leaves': 60,
        'min_data_in_leaf': 60,
        "boosting": "gbdt",
        'objective': 'binary',
        "metric": 'auc',
        'max_depth': -1,
        'learning_rate': 0.2,
        "feature_fraction": 0.8,
        "bagging_freq": 1,
        "bagging_fraction": 0.8,
        "bagging_seed": 11,
        "lambda_l1": 0.1,
        "random_state": 133,
        "verbosity": -1
    },
    'logical_cores_gpu': {
        'num_threads': 56,
        'device': 'gpu',
        'num_leaves': 60,
        'min_data_in_leaf': 60,
        "boosting": "gbdt",
        'objective': 'binary',
        "metric": 'auc',
        'max_depth': -1,
        'learning_rate': 0.2,
        "feature_fraction": 0.8,
        "bagging_freq": 1,
        "bagging_fraction": 0.8,
        "bagging_seed": 11,
        "lambda_l1": 0.1,
        "random_state": 133,
        "verbosity": -1
    }
}

max_iter = 3
folds_nr = 3

folds = KFold(n_splits=folds_nr, shuffle=True, random_state=15)
oof = np.zeros(len(train))
categorical_columns = [
    c for c in categorical_columns if c not in ['MachineIdentifier']]

features = [c for c in train.columns if c not in ['MachineIdentifier']]

for task_name, param in params.items():
    print("task {} started: {}".format(task_name, time.strftime("%b %d %Y %H:%M:%S")))
    predictions = np.zeros(len(test))
    feature_importance_df = pd.DataFrame()
    score = [0 for _ in range(folds.n_splits)]

    print("STARTING K-FOLD CV")
    for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):
        print("task {} starting fold nr {} at: {}".format(task_name, fold_, time.strftime("%b %d %Y %H:%M:%S")))
        trn_data = lgb.Dataset(train.iloc[trn_idx][features],
                               label=target.iloc[trn_idx],
                               categorical_feature=categorical_columns
                               )
        val_data = lgb.Dataset(train.iloc[val_idx][features],
                               label=target.iloc[val_idx],
                               categorical_feature=categorical_columns
                               )

        num_round = 5200
        clf = lgb.train(param,
                        trn_data,
                        num_round,
                        valid_sets=[trn_data, val_data],
                        verbose_eval=100,
                        early_stopping_rounds=200)

        oof[val_idx] = clf.predict(
            train.iloc[val_idx][features], num_iteration=clf.best_iteration)

        fold_importance_df = pd.DataFrame()
        fold_importance_df["feature"] = features
        fold_importance_df["importance"] = clf.feature_importance(
            importance_type='gain')
        fold_importance_df["fold"] = fold_ + 1
        feature_importance_df = pd.concat(
            [feature_importance_df, fold_importance_df], axis=0)

        # we perform predictions by chunks
        initial_idx = 0
        chunk_size = 1000000
        current_pred = np.zeros(len(test))
        while initial_idx < test.shape[0]:
            final_idx = min(initial_idx + chunk_size, test.shape[0])
            idx = range(initial_idx, final_idx)
            current_pred[idx] = clf.predict(
                test.iloc[idx][features], num_iteration=clf.best_iteration)
            initial_idx = final_idx
        predictions += current_pred / min(folds.n_splits, max_iter)

        score[fold_] = metrics.roc_auc_score(target.iloc[val_idx], oof[val_idx])
        print("task {} finished fold nr {} at: {}".format(task_name, fold_, time.strftime("%b %d %Y %H:%M:%S")))

        if fold_ == max_iter - 1:
            break

    print("task {} finished 3 FOLDS: {}".format(task_name, time.strftime("%b %d %Y %H:%M:%S")))        
    if (folds.n_splits == max_iter):
        cv_score = metrics.roc_auc_score(target, oof)
    else:
        cv_score = sum(score) / max_iter

    cv_score_printable = "{:<8.5f}".format(cv_score)
    print("CV score: {}".format(cv_score_printable))

    cv_score_printable = cv_score_printable.replace(".", "")
    cv_score_printable = cv_score_printable.strip()


    # Feature importance
    cols = (feature_importance_df[["feature", "importance"]]
            .groupby("feature")
            .mean()
            .sort_values(by="importance", ascending=False)[:1000].index)

    best_features = feature_importance_df.loc[
        feature_importance_df.feature.isin(cols)]

    plt.figure(figsize=(14, 25))
    sns.barplot(x="importance",
                y="feature",
                data=best_features.sort_values(by="importance",
                                               ascending=False))
    plt.title('LightGBM Features (avg over folds)')
    plt.tight_layout()
    plt.savefig(
        '../img/e{}_lgbm_importances_{}.png'.format(experinment_nr, cv_score_printable))
    feature_importance_df.to_csv(
        '../EDA/e{}_lgbm_importances_{}.csv'.format(experinment_nr, cv_score_printable))


    # submit predictions

    sub_df = pd.read_csv('../input/sample_submission.csv')
    sub_df["HasDetections"] = predictions

    model_dir = '../output'


    model_name = 'submit_e{}_cv{}_{}.csv.gz'.format(
        experinment_nr, cv_score_printable, dt.now().strftime('%Y-%m-%d-%H-%M'))

    fname = os.path.join(model_dir, model_name)
    param_string = ', '.join(('{}: {}'.format(k, v) for k, v in param.items()))
    message = 'CV: {} DATA: {} LGBM params: {}'.format(
        cv_score_printable, train_fname, param_string)
    competition = 'microsoft-malware-prediction'

    sub_df.to_csv(fname, compression='gzip', index=False)
    #kaggle.api.competition_submit(os.path.abspath(fname), message, competition)
    print("task {} finished: {}".format(task_name, time.strftime("%b %d %Y %H:%M:%S")))


print("script finished: ", time.strftime("%b %d %Y %H:%M:%S"))
