# coding: utf-8
import warnings
import gc
import pickle
import time
import kaggle
import os


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import lightgbm as lgb
from sklearn.model_selection import StratifiedKFold

from sklearn import metrics


from multiprocessing import Manager, Process, Queue, current_process

"""
E69
- Target Encoded features
- smaller params
"""
print("script started: ", time.strftime("%b %d %Y %H:%M:%S"))


experinment_nr = 69
train_fname = '../input/train-encoded-full-corr-v2.pkl.gz'
test_fname = '../input/test-encoded-full-corr-v2.pkl.gz'

#train_fname = '../input/train_catboost.pkl.gz'
#test_fname = '../input/test_catboost.pkl.gz'

TRAIN = pd.read_pickle(train_fname, compression='gzip')
print("TRAIN LOADED")
train_mean = pd.read_pickle('../input/train_target_mean.pkl')
TRAIN = pd.concat([TRAIN, train_mean], axis=1)
del train_mean
gc.collect()
print("TRAIN PREPARED")


TARGET = pd.read_pickle('../input/target.pkl')

test_mean = pd.read_pickle('../input/test_target_mean.pkl')
TEST = pd.read_pickle(test_fname, compression='gzip')
TEST = pd.concat([TEST, test_mean], axis=1)
del test_mean
print("TEST LOADED")

FOLDS_NR = 5
JOBS_NR = 5
THREAD_NR = 6

folds = StratifiedKFold(n_splits=FOLDS_NR, shuffle=True, random_state=15)
oof = np.zeros(len(TRAIN))
FEATURES = [c for c in TRAIN.columns if c not in ['MachineIdentifier']]

predictions = np.zeros(len(TEST))
feature_importance_df = pd.DataFrame()
score = [0 for _ in range(folds.n_splits)]
work_queue = Queue()
done_queue = Queue()
processes = []



PARAM = {
    'num_leaves': 2048,
    'max_bin': 2000,
    'num_threads': THREAD_NR,
    'objective': 'binary',
    'max_depth': -1,
    'learning_rate': 0.05,
    "boosting": "gbdt",
    "feature_fraction": 0.7,
    "bagging_freq": 1,
    "bagging_fraction": 0.7,
    "bagging_seed": 11,
    "metric": 'auc',
    "lambda_l1": 0.1,
    "random_state": 133,
    "verbosity": -1
}



def worker(work_queue, done_queue, predictions_cache, oof_cache, importance_cache, trn_idx_cache, val_idx_cache):
    """
    Worker si bere data z fronty, dokud tam nějaká jsou a volá na ně procesní funkci
    """

    try:
        for data in iter(work_queue.get, 'STOP'):
            print("{} GOT DATA".format(current_process().name), data)

            fold = int(data['fold'])

            print("fold", fold, "type", type(fold))

            trn_idx = trn_idx_cache[fold]
            val_idx = val_idx_cache[fold]
            

            # create dataset for lightgbm
            trn_data = lgb.Dataset(TRAIN.iloc[trn_idx][FEATURES],
                                   label=TARGET.iloc[trn_idx]
                                   )
            val_data = lgb.Dataset(TRAIN.iloc[val_idx][FEATURES],
                                   label=TARGET.iloc[val_idx]
                                   )
            # create classifier
            clf = lgb.train(PARAM,
                            trn_data,
                            data['num_round'],
                            valid_sets=[trn_data, val_data],
                            verbose_eval=50,
                            early_stopping_rounds=200)

            # predict
            oof_fo = clf.predict(
                    TRAIN.iloc[val_idx][FEATURES], num_iteration=clf.best_iteration)

            oof_cache[fold] = oof_fo
            importance_cache[fold] = clf.feature_importance(importance_type='gain')

            print("{} finished training".format(current_process().name))

            # we perform predictions by chunks
            initial_idx = 0
            chunk_size = 1000000
            current_pred = np.zeros(len(TEST))
            while initial_idx < TEST.shape[0]:
                final_idx = min(initial_idx + chunk_size, TEST.shape[0])
                idx = range(initial_idx, final_idx)
                current_pred[idx] = clf.predict(
                    TEST.iloc[idx][FEATURES], num_iteration=clf.best_iteration)
                initial_idx = final_idx

            predictions_cache[fold] = current_pred 
            
            result = fold

            print("{} finished prediction".format(current_process().name))
            print("storing result", result)

            done_queue.put(result)
    
    except Exception as e:
        done_queue.put("{} failed with: {}".format(
            current_process().name, e))
    
    print("{} finished".format(current_process().name), time.strftime("%b %d %Y %H:%M:%S"))
    return True

with Manager() as manager:
    
    predictions_cache = manager.dict()
    oof_cache = manager.dict()
    importance_cache = manager.dict()
    trn_idx_cache = manager.dict()
    val_idx_cache = manager.dict()    


    start = time.time()
    print("STARTING PARALLEL K-FOLD CV", time.strftime("%b %d %Y %H:%M:%S"))
    for fold_, (trn_idx, val_idx) in enumerate(folds.split(TRAIN.values, TARGET.values)):
        print("fold n°{}".format(fold_))

        num_round = 10000

        trn_idx_cache[fold_] = trn_idx
        val_idx_cache[fold_] = val_idx

        data = {
            'fold': fold_,
            'num_round': num_round
        }

        work_queue.put(data)
        

    for w in range(JOBS_NR):
        # nastartujeme nový process - worker musí dostat frontu jako argument
        p = Process(target=worker, args=(work_queue, done_queue, predictions_cache, oof_cache, importance_cache, trn_idx_cache, val_idx_cache))
        p.start()
        processes.append(p)
        print("started process", w)
        # STOP příkaz musíme přidat pro každý process který jsme vytvořili
        work_queue.put('STOP')

        
    for p in processes:
        p.join()
        print('joined', p)



    done_queue.put('STOP')

    print("training completed: ", time.strftime("%b %d %Y %H:%M:%S"))

    print("training time", time.time() - start)

    print("starting final prediction: ", time.strftime("%b %d %Y %H:%M:%S"))
    start = time.time()

    for result in iter(done_queue.get, 'STOP'):
        print("RESULT", result)
        fold_nr = int(result)

    
        val_idx = val_idx_cache[fold_nr]
        

        oof[val_idx] = oof_cache[fold_nr]
        
        fold_importance_df = pd.DataFrame()
        fold_importance_df["feature"] = FEATURES
        fold_importance_df["importance"] = importance_cache[fold_nr]
        fold_importance_df["fold"] = fold_nr + 1
        feature_importance_df = pd.concat(
            [feature_importance_df, fold_importance_df], axis=0)

        predictions += predictions_cache[fold_nr] / FOLDS_NR

        score[fold_nr] = metrics.roc_auc_score(TARGET.iloc[val_idx], oof[val_idx])
      
    print("prediction merge completed: ", time.strftime("%b %d %Y %H:%M:%S"))

    print("prediction time", time.time() - start)


cv_score = metrics.roc_auc_score(TARGET, oof)

cv_score_printable = "{:<8.5f}".format(cv_score)
print("CV score: {}".format(cv_score_printable))

cv_score_printable = cv_score_printable.replace(".", "")
cv_score_printable = cv_score_printable.strip()


# Feature importance
cols = (feature_importance_df[["feature", "importance"]]
        .groupby("feature")
        .mean()
        .sort_values(by="importance", ascending=False)[:1000].index)

best_FEATURES = feature_importance_df.loc[
    feature_importance_df.feature.isin(cols)]

plt.figure(figsize=(14, 25))
sns.barplot(x="importance",
            y="feature",
            data=best_FEATURES.sort_values(by="importance",
                                           ascending=False))
plt.title('LightGBM Features (avg over folds)')
plt.tight_layout()
plt.savefig(
    '../img/e{}_lgbm_importances_{}.png'.format(experinment_nr, cv_score_printable))
feature_importance_df.to_csv(
    '../EDA/importances/e{}_lgbm_importances_{}.csv'.format(experinment_nr, cv_score_printable))


# submit predictions

sub_df = pd.read_csv('../input/sample_submission.csv')
sub_df["HasDetections"] = predictions

model_dir = '../output'


model_name = 'submit_e{}_cv{}.csv.gz'.format(
    experinment_nr, cv_score_printable)

fname = os.path.join(model_dir, model_name)
param_string = ', '.join(('{}: {}'.format(k, v) for k, v in PARAM.items()))
message = 'CV: {} DATA: {} LGBM PARAMs: {}'.format(
    cv_score_printable, train_fname, param_string)
competition = 'microsoft-malware-prediction'

sub_df.to_csv(fname, compression='gzip', index=False)
kaggle.api.competition_submit(os.path.abspath(fname), message, competition)

print("script finished: ", time.strftime("%b %d %Y %H:%M:%S"))
