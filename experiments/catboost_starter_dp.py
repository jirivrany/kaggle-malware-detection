
# coding: utf-8

# ### Fabien Daniel's https://www.kaggle.com/fabiendaniel/detecting-malwares-with-lgbm has been supremely helpful
# 
# ### I have removed a lot of low importance features, and have kept a large learning rate, just for trial purposes. I will report on how much the score improves once I run the entire code (more features, lower lr, higher max_iter etc) on my local machine. 
# 
# ### Reduced train and test sets courtesy Konrad Banachewicz's kernel (https://www.kaggle.com/konradb/shrinking-the-data)
# ### Original idea for loading dtypes courtesy Theo Viel (https://www.kaggle.com/theoviel/load-the-totality-of-the-data)

# In[ ]:


def reduce_mem_usage(df, verbose=True):
    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
    start_mem = df.memory_usage().sum() / 1024**2    
    for col in df.columns:
        col_type = df[col].dtypes
        if col_type in numerics:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)  
            else:
                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                    df[col] = df[col].astype(np.float16)
                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)    
    end_mem = df.memory_usage().sum() / 1024**2
    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))
    return df


# In[ ]:


import warnings
import gc
import time
import sys
import datetime


import numpy as np 
import pandas as pd 
import catboost as cb


from sklearn.model_selection import KFold
from sklearn.metrics import roc_auc_score


pd.options.mode.chained_assignment = None
pd.options.display.max_columns = 999

from tqdm import tqdm

print("script started: ", time.strftime("%b %d %Y %H:%M:%S"))



# save data in case that model crashes
train = pd.read_pickle('../input/train_catboost.pkl.gz', compression='gzip')
test = pd.read_pickle('../input/test_catboost.pkl.gz', compression='gzip')
target = pd.read_pickle('../input/target.pkl.gz', compression='gzip')

train.drop(['MachineIdentifier'], axis=1, inplace=True)
test.drop(['MachineIdentifier'], axis=1, inplace=True)


true_numerical_columns = [
    'Census_ProcessorCoreCount',
    'Census_PrimaryDiskTotalCapacity',
    'Census_SystemVolumeTotalCapacity',
    'Census_TotalPhysicalRAM',
    'Census_InternalPrimaryDiagonalDisplaySizeInInches',
    'Census_InternalPrimaryDisplayResolutionHorizontal',
    'Census_InternalPrimaryDisplayResolutionVertical',
    'Census_InternalBatteryNumberOfCharges'
]

binary_variables = [c for c in train.columns if train[c].nunique() == 2]

categorical_columns = [c for c in train.columns 
                       if (c not in true_numerical_columns) & (c not in binary_variables)]


print(train[categorical_columns].head())

print(train[categorical_columns].tail())

print("data preparation finished: ", time.strftime("%b %d %Y %H:%M:%S"))



print(train[categorical_columns].isna().sum())   


## cols_to_keep = list(set(train.columns) & set(test.columns))
## train = train[cols_to_keep]
## test = test[cols_to_keep]
##train = reduce_mem_usage(train)
##test = reduce_mem_usage(test)
#
#
## In[ ]:
#
#def column_index(df, query_cols):
#    """
#    prepare categorical features index
#    """
#    cols = df.columns.values
#    sidx = np.argsort(cols)
#    return sidx[np.searchsorted(cols,query_cols,sorter=sidx)]
#
#
## Let's try a CatBoost just for 3 iterations
#
#max_iter=3
#
#features = train.columns
#
#folds = KFold(n_splits=5, shuffle=True, random_state=15)
#oof_cb = np.zeros(len(train))
#predictions_cb = np.zeros(len(test))
#score = [0 for _ in range(folds.n_splits)]
#
## Prepare Categorical Variables
#categorical_features_pos = column_index(train, categorical_columns)
#print(categorical_features_pos)
#
#for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):
#    print('-')
#    print("Fold {}".format(fold_ + 1))
#    X_train, y_train = train[features].iloc[trn_idx], target.iloc[trn_idx]
#    X_valid, y_valid = train[features].iloc[val_idx], target.iloc[val_idx]
#    
#    
#    model = cb.CatBoostClassifier(
#        learning_rate = 0.25,
#        iterations = 10000,
#        eval_metric = 'AUC',
#        allow_writing_files = False,
#        od_type = 'Iter',
#        bagging_temperature = 0.3,
#        random_strength = 0.1,
#        l2_leaf_reg = 0.1,
#        depth = 8,
#        od_wait = 20, 
#        task_type='GPU')
#    
#            
#    # Fit
#    model.fit(
#        X_train, y_train,
#        eval_set=[(X_train, y_train), (X_valid, y_valid)],
#        early_stopping_rounds=50,
#        cat_features=categorical_features_pos,
#        verbose_eval=100
#    )
#    
#    oof_cb[val_idx] = model.predict(X_valid)
#    predictions_cb += model.predict(test[features]) / min(folds.n_splits, max_iter)    
#    
#    score[fold_] = metrics.roc_auc_score(target.iloc[val_idx], oof_cb[val_idx])
#    if fold_ == max_iter - 1: break
#        
#if (folds.n_splits == max_iter):
#    print("CV score: {:<8.5f}".format(metrics.roc_auc_score(target, oof_cb)))
#else:
#     print("CV score: {:<8.5f}".format(sum(score) / max_iter))
#
#
## In[ ]:
#
#sub_df = pd.read_csv('../input/sample_submission.csv')
#sub_df["HasDetections"] = predictions_cb
#
#sub_df.to_csv("../output/submit-catboost-cv{:6f}.csv".format(score), index=False)
#
#print("script finished: ", time.strftime("%b %d %Y %H:%M:%S"))
#
