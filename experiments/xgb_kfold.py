# coding: utf-8
import os
import time
import gc


import kaggle
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


from xgboost import XGBClassifier
from sklearn.model_selection import KFold
from sklearn import metrics
from datetime import datetime as dt

print("script started: ", time.strftime("%b %d %Y %H:%M:%S"))


experiment_nr = 58
random_state = 42

train_fname = '../input/train-encoded-full-corr-v2.pkl'
test_fname = '../input/test-encoded-full-corr-v2.pkl'

train = pd.read_pickle(train_fname)
print("TRAIN LOADED")

target = pd.read_pickle('../input/target.pkl')


test = pd.read_pickle(test_fname)
print("TEST LOADED")


gc.collect()

max_iter = 3
folds_nr = 3

folds = KFold(n_splits=folds_nr, shuffle=True, random_state=15)
oof = np.zeros(len(train))

features = [c for c in train.columns if c not in ['MachineIdentifier']]
predictions = np.zeros(len(test))
start = time.time()
feature_importance_df = pd.DataFrame()
start_time = time.time()
score = [0 for _ in range(folds.n_splits)]

train = train[features]
test = test[features]

print("STARTING K-FOLD CV")
for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):
    print("fold nÂ°{}".format(fold_))

    x_train = train.iloc[trn_idx]
    y_train = target.iloc[trn_idx]

    x_val = train.iloc[val_idx]
    y_val = target.iloc[val_idx]

    clf = XGBClassifier(
        max_depth=10,
        tree_method='gpu_hist',
        n_gpus=10,
        nthread=20,
        verbosity=2,
        n_estimators=2000,
        colsample_bytree=0.7,
        subsample=0.7,
        gamma=0.2,
        learning_rate=0.1,
        seed=42)

    clf.fit(
        x_train,
        y_train,
        eval_metric="auc",
        eval_set=[(x_train, y_train), (x_val, y_val)],
        verbose=True,
        early_stopping_rounds=100)


    best_iteration = clf.get_booster().best_ntree_limit

    oof[val_idx] = clf.predict(
        train.iloc[val_idx], , ntree_limit=best_iteration)

    # we perform predictions by chunks
    initial_idx = 0
    chunk_size = 1000000
    current_pred = np.zeros(len(test))
    while initial_idx < test.shape[0]:
        final_idx = min(initial_idx + chunk_size, test.shape[0])
        idx = range(initial_idx, final_idx)
        current_pred[idx] = clf.predict(test.iloc[idx], , ntree_limit=best_iteration)
        initial_idx = final_idx
    predictions += current_pred / min(folds.n_splits, max_iter)

    score[fold_] = metrics.roc_auc_score(target.iloc[val_idx], oof[val_idx])
    if fold_ == max_iter - 1:
        break

if (folds.n_splits == max_iter):
    cv_score = metrics.roc_auc_score(target, oof)
else:
    cv_score = sum(score) / max_iter

cv_score_printable = "{:<8.5f}".format(cv_score)
print("CV score: {}".format(cv_score_printable))

cv_score_printable = cv_score_printable.replace(".", "")
cv_score_printable = cv_score_printable.strip()


# submit predictions

sub_df = pd.read_csv('../input/sample_submission.csv')
sub_df["HasDetections"] = predictions

model_dir = '../output'


model_name = 'submit_xgb_e{}_cv{}_{}.csv.gz'.format(
    experiment_nr, cv_score_printable, dt.now().strftime('%Y-%m-%d-%H-%M'))

fname = os.path.join(model_dir, model_name)
# param_string = ', '.join(('{}: {}'.format(k, v)
#                          for k, v in lgb_params.items()))
# message = 'CV: {} DATA: {} LGBM params: {}'.format(
#    cv_score_printable, train_fname, param_string)
#competition = 'microsoft-malware-prediction'

sub_df.to_csv(fname, compression='gzip', index=False)
#kaggle.api.competition_submit(os.path.abspath(fname), message, competition)

print("script finished: ", time.strftime("%b %d %Y %H:%M:%S"))
