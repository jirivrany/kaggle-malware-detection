# coding: utf-8
import gc
import pickle
import numpy as np
import pandas as pd
from itertools import combinations
from tqdm import tqdm

import utils
import conversions

cols = [
    #'EngineVersion',
    #'AppVersion',
    #'AvSigVersion',
    'AVProductStatesIdentifier',
    'AVProductsInstalled',
    'SmartScreen',
    'Census_OEMModelIdentifier',
    'Census_ProcessorModelIdentifier',
    'Census_PrimaryDiskTotalCapacity',
    'Census_TotalPhysicalRAM',
    'Census_InternalPrimaryDiagonalDisplaySizeInInches',
    'Census_FirmwareVersionIdentifier'
]


#train = pd.read_csv('../input/train.csv', usecols=cols, dtype=utils.DTYPES)
train = pd.read_pickle('../input/train.pkl')
print("TRAIN LOADED")

cols = train.columns

target = 'HasDetections'
cols.remove(target)

#test = pd.read_csv('../input/test.csv', usecols=cols, dtype=utils.DTYPES)
test = pd.read_pickle('../input/test.pkl')
print("TEST LOADED")

#train.to_pickle('../input/train_cols_for_target_mean.pkl')
#test.to_pickle('../input/test_cols_for_target_mean.pkl')

new_cols = []

cols.remove('MachineIdentifier')

def add_noise(series, noise_level):
    return series * (1 + noise_level * np.random.randn(len(series)))

def target_encode(trn_series=None, 
                  tst_series=None, 
                  target=None, 
                  min_samples_leaf=1, 
                  smoothing=1,
                  noise_level=0):
    """
    Smoothing is computed like in the following paper by Daniele Micci-Barreca
    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf
    trn_series : training categorical feature as a pd.Series
    tst_series : test categorical feature as a pd.Series
    target : target data as a pd.Series
    min_samples_leaf (int) : minimum samples to take category average into account
    smoothing (int) : smoothing effect to balance categorical average vs prior  
    """ 
    assert len(trn_series) == len(target)
    assert trn_series.name == tst_series.name
    temp = pd.concat([trn_series, target], axis=1)
    # Compute target mean 
    averages = temp.groupby(by=trn_series.name)[target.name].agg(["mean", "count"])
    # Compute smoothing
    smoothing = 1 / (1 + np.exp(-(averages["count"] - min_samples_leaf) / smoothing))
    # Apply average function to all target data
    prior = target.mean()
    # The bigger the count the less full_avg is taken into account
    averages[target.name] = prior * (1 - smoothing) + averages["mean"] * smoothing
    averages.drop(["mean", "count"], axis=1, inplace=True)
    # Apply averages to trn and tst series
    ft_trn_series = pd.merge(
        trn_series.to_frame(trn_series.name),
        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),
        on=trn_series.name,
        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)
    # pd.merge does not keep the index so restore it
    ft_trn_series.index = trn_series.index 
    ft_tst_series = pd.merge(
        tst_series.to_frame(tst_series.name),
        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),
        on=tst_series.name,
        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)
    # pd.merge does not keep the index so restore it
    ft_tst_series.index = tst_series.index
    return add_noise(ft_trn_series, noise_level), add_noise(ft_tst_series, noise_level)


for col in tqdm(cols):
    print(col)
    new_feature = 'fe_{}_target_mean_enc'.format(col)
    trn, sub = target_encode(train[col], 
                         test[col], 
                         target=train[target], 
                         min_samples_leaf=100,
                         smoothing=10,
                         noise_level=0.01)
    train[new_feature] = trn
    test[new_feature] = sub

    new_cols.append(new_feature)

print("computed, now reducing size")

train = train[new_cols]
test = test[new_cols]

train = utils.reduce_mem_usage(train)
test = utils.reduce_mem_usage(test)

print("saving results")

train.to_pickle('../input/train_target_mean_full.pkl')
test.to_pickle('../input/test_target_mean_full.pkl')

