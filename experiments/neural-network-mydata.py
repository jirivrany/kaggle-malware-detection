
# IMPORT LIBRARIES
import pandas as pd
import numpy as np
import math
import os
import gc
import time

import os
os.environ['CUDA_VISIBLE_DEVICES']="1"


from keras import callbacks
from sklearn.metrics import roc_auc_score

from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense, Dropout, BatchNormalization, Activation
from keras.callbacks import LearningRateScheduler
from keras.optimizers import Adam
from keras.utils import multi_gpu_model

print("script started: ", time.strftime("%b %d %Y %H:%M:%S"))

# LOAD CSV FILE
train = pd.read_pickle('../input/train-encoded-full-corr-v2.pkl')
print('Loaded', len(train), 'rows of TRAIN.CSV!')
## DOWNSAMPLE
sm = 200000
train = train.sample(sm)
print('Only using', sm, 'rows to train and validate')
x = gc.collect()


target = pd.read_pickle('../input/target.pkl')

class printAUC(callbacks.Callback):

    def __init__(self, X_train, y_train, model_file_name):
        super(printAUC, self).__init__()
        self.bestAUC = 0
        self.X_train = X_train
        self.y_train = y_train
        self.model_fname = model_file_name

    def on_epoch_end(self, epoch, logs={}):
        pred = self.model.predict(np.array(self.X_train))
        auc = roc_auc_score(self.y_train, pred)
        print("Train AUC: " + str(auc))
        pred = self.model.predict(self.validation_data[0])
        auc = roc_auc_score(self.validation_data[1], pred)
        print("Validation AUC: " + str(auc))
        if (self.bestAUC < auc):
            self.bestAUC = auc
            self.model.save(self.model_fname, overwrite=True)
        return


model_save_name = "../models/best_net_md.h5"

# SPLIT TRAIN AND VALIDATION SET
X_train, X_val, Y_train, Y_val = train_test_split(
    train, target, test_size=0.1)

# BUILD MODEL
model = Sequential()
model.add(Dense(100, input_dim=len(train.shape[1])))
model.add(Dropout(0.4))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dense(256))
model.add(Dropout(0.4))
model.add(BatchNormalization())
model.add(Dense(256))
model.add(Dropout(0.4))
model.add(BatchNormalization())
model.add(Dense(100))
model.add(Dropout(0.4))
model.add(BatchNormalization())
model.add(Activation('relu'))
model.add(Dense(1, activation='sigmoid'))

#model = multi_gpu_model(model, gpus=8)
model.compile(optimizer=Adam(lr=0.5),
              loss="binary_crossentropy", metrics=["accuracy"])
annealer = LearningRateScheduler(lambda x: 1e-2 * 0.95 ** x)

print(model.summary())


# TRAIN MODEL
model.fit(
    X_train,
    Y_train,
    batch_size=64,
    epochs=2,
    callbacks=[
      annealer,
      printAUC(X_train, Y_train, model_save_name)
    ],
    validation_data=(X_val, Y_val),
    verbose=2)



del train
del X_train, X_val, Y_train, Y_val
x = gc.collect()

# LOAD BEST SAVED NET
from keras.models import load_model
model = load_model(model_save_name)

pred = np.zeros((7853253, 1))
id = 1
chunksize = 2000000
for df_test in pd.read_pickle('../input/test-encoded-full-corr-v2.pkl'):
    print('Loaded', len(df_test), 'rows of TEST.CSV!')
    # PREDICT TEST
    end = (id) * chunksize
    if end > 7853253:
        end = 7853253
    pred[(id - 1) * chunksize:end] = model.predict(df_test)
    print('  encoded and predicted part', id)
    id += 1


# In[ ]:


# SUBMIT TO KAGGLE
sub_df = pd.read_csv('../input/sample_submission.csv')
sub_df["HasDetections"] = pred
sub_df.to_csv('../output/sub-nn-02-mydata.csv', index=False)

print("script finished: ", time.strftime("%b %d %Y %H:%M:%S"))